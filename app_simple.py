#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
e-EFKA PDF Data Extractor - Simple Version
Î‘Ï€Î»Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î· Î­ÎºÎ´Î¿ÏƒÎ· Î¼Îµ ÎºÎ±Î¸Î±ÏÎ® ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
"""

import streamlit as st
import pandas as pd
import io
import tempfile
import os
import re
from pathlib import Path

# Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î®Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏÎ½ PDF readers
try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False

try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
except ImportError:
    PYMUPDF_AVAILABLE = False

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÏƒÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(
    page_title="e-EFKA PDF Extractor",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .upload-section {
        background-color: #f8f9fa;
        padding: 2rem;
        border-radius: 10px;
        border: 2px dashed #dee2e6;
        text-align: center;
        margin: 2rem 0;
    }
    .success-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        margin: 1rem 0;
    }
    .info-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
        margin: 1rem 0;
    }
    .warning-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        margin: 1rem 0;
    }
    .results-section {
        background-color: #ffffff;
        padding: 2rem;
        border-radius: 10px;
        border: 1px solid #dee2e6;
        margin: 2rem 0;
    }
</style>
""", unsafe_allow_html=True)

def extract_tables_adaptive(pdf_path):
    """
    Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€Î¹Î½Î¬ÎºÏ‰Î½ Î¼Îµ Ï€Î¿Î»Î»Î­Ï‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚
    """
    import pdfplumber
    
    all_tables = []
    
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
        st.info(f"ğŸ“„ Î£ÏÎ½Î¿Î»Î¿ ÏƒÎµÎ»Î¯Î´Ï‰Î½: {total_pages}")
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for page_num, page in enumerate(pdf.pages):
            if page_num < 1:  # Î Î±ÏÎ±ÎºÎ¬Î¼Ï€Ï„Î¿Ï…Î¼Îµ Ï„Î·Î½ Ï€ÏÏÏ„Î· ÏƒÎµÎ»Î¯Î´Î±
                continue
                
            # Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ· progress
            progress = (page_num - 1) / (total_pages - 2) if total_pages > 2 else 0
            progress_bar.progress(progress)
            status_text.text(f"ğŸ” Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÏƒÎµÎ»Î¯Î´Î±Ï‚ {page_num + 1} Î±Ï€ÏŒ {total_pages - 1}...")
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 1: ÎšÎ±Î½Î¿Î½Î¹ÎºÎ® ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€Î¹Î½Î¬ÎºÏ‰Î½
            tables = page.extract_tables()
            
            if len(tables) >= 2:
                second_table = tables[1]
                if second_table and len(second_table) > 1:
                    df = pd.DataFrame(second_table[1:], columns=second_table[0])
                    df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                    all_tables.append(df)
                    st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚")
                    continue
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 2: Î•Î¾Î±Î³Ï‰Î³Î® Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚
            try:
                tables_alt = page.extract_tables(table_settings={
                    "vertical_strategy": "lines_strict",
                    "horizontal_strategy": "lines_strict"
                })
                
                if len(tables_alt) >= 2:
                    second_table = tables_alt[1]
                    if second_table and len(second_table) > 1:
                        df = pd.DataFrame(second_table[1:], columns=second_table[0])
                        df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                        all_tables.append(df)
                        st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚")
                        continue
            except Exception:
                pass
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 3: Î•Î¾Î±Î³Ï‰Î³Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Ï€Î¹Î½Î¬ÎºÏ‰Î½
            try:
                all_tables_page = page.extract_tables()
                if all_tables_page:
                    largest_table = max(all_tables_page, key=len)
                    if largest_table and len(largest_table) > 1:
                        df = pd.DataFrame(largest_table[1:], columns=largest_table[0])
                        df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                        all_tables.append(df)
                        st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚")
                        continue
            except Exception:
                pass
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 4: Text-based parsing
            try:
                text = page.extract_text()
                if text and len(text) > 100:
                    table_data = parse_text_for_tables(text, page_num + 1)
                    if table_data and len(table_data) > 1:
                        df = pd.DataFrame(table_data[1:], columns=table_data[0])
                        df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                        all_tables.append(df)
                        st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚")
                        continue
            except Exception:
                pass
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 5: Î•Î¾Î±Î³Ï‰Î³Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Ï€Î¹Î½Î¬ÎºÏ‰Î½ (fallback)
            try:
                all_tables_page = page.extract_tables()
                if all_tables_page:
                    for table_idx, table in enumerate(all_tables_page):
                        if table and len(table) > 1:
                            df = pd.DataFrame(table[1:], columns=table[0])
                            df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                            df['Î Î¯Î½Î±ÎºÎ±Ï‚'] = table_idx + 1
                            all_tables.append(df)
                            st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (Ï€Î¯Î½Î±ÎºÎ±Ï‚ {table_idx + 1})")
                            break
            except Exception:
                pass
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 6: PyMuPDF fallback
            if PYMUPDF_AVAILABLE:
                try:
                    import fitz
                    doc = fitz.open(pdf_path)
                    page_pymupdf = doc[page_num]
                    tables_pymupdf = page_pymupdf.find_tables()
                    
                    if len(tables_pymupdf) >= 2:
                        second_table = tables_pymupdf[1]
                        table_data = second_table.extract()
                        if table_data and len(table_data) > 1:
                            df = pd.DataFrame(table_data[1:], columns=table_data[0])
                            df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                            all_tables.append(df)
                            st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚")
                            doc.close()
                            continue
                    doc.close()
                except Exception:
                    pass
            
            st.warning(f"âš ï¸ Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï€Î¯Î½Î±ÎºÎ±Ï‚")
        
        # Î¤ÎµÎ»Î¹ÎºÏŒ progress
        progress_bar.progress(1.0)
        status_text.text("âœ… Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ!")
    
    return all_tables

def parse_text_for_tables(text, page_num):
    """
    Î‘Î½Î±Î»ÏÎµÎ¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î³Î¹Î± Î½Î± Î²ÏÎµÎ¹ Ï€Î¯Î½Î±ÎºÎµÏ‚
    """
    lines = text.split('\n')
    
    # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± Î³ÏÎ±Î¼Î¼Î­Ï‚ Ï€Î¿Ï… Î¼Î¿Î¹Î¬Î¶Î¿Ï…Î½ Î¼Îµ Ï€Î¯Î½Î±ÎºÎ±
    table_lines = []
    in_table = False
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± patterns Ï€Î¿Ï… Ï…Ï€Î¿Î´ÎµÎ¹ÎºÎ½ÏÎ¿Ï…Î½ Ï€Î¯Î½Î±ÎºÎ±
        if (re.search(r'\d{1,2}/\d{1,2}/\d{4}', line) or  # Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯ÎµÏ‚
            re.search(r'[\d,]+\.\d{2}', line) or  # Î Î¿ÏƒÎ¬
            line.count(' ') > 3 or  # Î Î¿Î»Î»Î¬ ÎºÎµÎ½Î¬
            '\t' in line):  # Tabs
            
            table_lines.append(line)
            in_table = True
        elif in_table and len(table_lines) > 0:
            # Î‘Î½ ÎµÎ¯Ï‡Î±Î¼Îµ Î²ÏÎµÎ¹ Ï€Î¯Î½Î±ÎºÎ± Î±Î»Î»Î¬ Ï„ÏÏÎ± Î´ÎµÎ½ Î²ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
            if len(table_lines) > 5:  # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ Î±ÏÎºÎµÏ„Î­Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚
                break
            else:
                table_lines = []  # Reset Î±Î½ Î´ÎµÎ½ Î­Ï‡Î¿Ï…Î¼Îµ Î±ÏÎºÎµÏ„Î­Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚
                in_table = False
    
    if len(table_lines) < 3:
        return None
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ headers
    headers = ['Î£Ï„Î®Î»Î·_1', 'Î£Ï„Î®Î»Î·_2', 'Î£Ï„Î®Î»Î·_3', 'Î£Ï„Î®Î»Î·_4', 'Î£Ï„Î®Î»Î·_5', 'Î£Ï„Î®Î»Î·_6']
    
    # ÎœÎµÏ„Î±Ï„ÏÎ­Ï€Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚ ÏƒÎµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    data = [headers]
    for line in table_lines:
        # Î§Ï‰ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î· Î³ÏÎ±Î¼Î¼Î® ÏƒÎµ ÏƒÏ„Î®Î»ÎµÏ‚
        parts = line.split()
        if len(parts) >= 3:  # Î‘Î½ Î­Ï‡ÎµÎ¹ Î±ÏÎºÎµÏ„Î­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚
            # Î£Ï…Î¼Ï€Î»Î·ÏÏÎ½Î¿Ï…Î¼Îµ Î¼Îµ ÎºÎµÎ½Î¬ Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
            while len(parts) < len(headers):
                parts.append('')
            data.append(parts[:len(headers)])
    
    return data if len(data) > 1 else None

def extract_efka_data(uploaded_file):
    """
    Î•Î¾Î±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ PDF Î±ÏÏ‡ÎµÎ¯Î¿
    """
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î­Î½Î± Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_path = tmp_file.name
    
    try:
        # Î•Î¾Î¬Î³Î¿Ï…Î¼Îµ Ï€Î¯Î½Î±ÎºÎµÏ‚
        all_tables = extract_tables_adaptive(tmp_path)
        
        if not all_tables:
            st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€Î¯Î½Î±ÎºÎµÏ‚ ÏƒÏ„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿")
            return pd.DataFrame()
        
        # Î£Ï…Î½Î´Ï…Î¬Î¶Î¿Ï…Î¼Îµ ÏŒÎ»Î± Ï„Î± DataFrames
        with st.spinner("Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½..."):
            combined_df = pd.concat(all_tables, ignore_index=True)
        
        return combined_df
    
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎ¾Î±Î³Ï‰Î³Î®: {str(e)}")
        return pd.DataFrame()
    
    finally:
        # Î”Î¹Î±Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)

def main():
    """ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï„Î·Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚"""
    
    # Header
    st.markdown('<h1 class="main-header">ğŸ“„ e-EFKA PDF Data Extractor</h1>', unsafe_allow_html=True)
    
    # Î‘ÏÏ‡Î¹ÎºÎ® ÎºÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ· - Î±Î½Î­Î²Î±ÏƒÎ¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï…
    if 'file_uploaded' not in st.session_state:
        st.session_state['file_uploaded'] = False
    if 'processing_done' not in st.session_state:
        st.session_state['processing_done'] = False
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Î½ÎµÎ²Î¬ÏƒÎ¼Î±Ï„Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…
    if not st.session_state['file_uploaded']:
        st.markdown('<div class="upload-section">', unsafe_allow_html=True)
        st.markdown("### ğŸ“¤ Î‘Î½Î­Î²Î±ÏƒÎ¼Î± PDF Î‘ÏÏ‡ÎµÎ¯Î¿Ï… e-EFKA")
        st.markdown("Î•Ï€Î¹Î»Î­Î¾Ï„Îµ Ï„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î¸Î­Î»ÎµÏ„Îµ Î½Î± Î±Î½Î±Î»ÏÏƒÎµÏ„Îµ")
        
        uploaded_file = st.file_uploader(
            "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ PDF Î±ÏÏ‡ÎµÎ¯Î¿",
            type=['pdf'],
            help="Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿ e-EFKA",
            label_visibility="collapsed"
        )
        
        if uploaded_file is not None:
            st.session_state['uploaded_file'] = uploaded_file
            st.session_state['file_uploaded'] = True
            st.success(f"âœ… Î‘Î½ÎµÎ²Î»Î®Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿: {uploaded_file.name}")
            st.info(f"ğŸ“Š ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {uploaded_file.size:,} bytes")
            st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎºÎ¿Ï…Î¼Ï€Î¹Î¿Ï ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚
    elif not st.session_state['processing_done']:
        st.markdown('<div class="upload-section">', unsafe_allow_html=True)
        st.markdown("### âœ… Î‘ÏÏ‡ÎµÎ¯Î¿ Î‘Î½ÎµÎ²Î»Î®Î¸Î·ÎºÎµ")
        st.success(f"ğŸ“„ {st.session_state['uploaded_file'].name}")
        st.info(f"ğŸ“Š ÎœÎ­Î³ÎµÎ¸Î¿Ï‚: {st.session_state['uploaded_file'].size:,} bytes")
        
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button("ğŸš€ Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± PDF", type="primary", use_container_width=True):
                st.session_state['processing_done'] = True
                st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÎºÎ±Î¹ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
    else:
        # Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±
        with st.spinner("Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± PDF Î±ÏÏ‡ÎµÎ¯Î¿Ï…..."):
            df = extract_efka_data(st.session_state['uploaded_file'])
        
        if not df.empty:
            st.session_state['extracted_data'] = df
            st.session_state['processing_done'] = True
            
            # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
            st.markdown('<div class="results-section">', unsafe_allow_html=True)
            st.markdown("### ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î•Î¾Î±Î³Ï‰Î³Î®Ï‚")
            
            # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î“ÏÎ±Î¼Î¼Î­Ï‚", len(df))
            with col2:
                st.metric("Î£Ï„Î®Î»ÎµÏ‚", len(df.columns))
            with col3:
                st.metric("Î£ÎµÎ»Î¯Î´ÎµÏ‚", df['Î£ÎµÎ»Î¯Î´Î±'].nunique() if 'Î£ÎµÎ»Î¯Î´Î±' in df.columns else 0)
            with col4:
                st.metric("ÎœÎ­Î³ÎµÎ¸Î¿Ï‚", f"{df.memory_usage(deep=True).sum() / 1024:.1f} KB")
            
            # Î Î¯Î½Î±ÎºÎ±Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (ÏŒÎ»Î± Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±, Ï‡Ï‰ÏÎ¯Ï‚ Ï†Î¯Î»Ï„ÏÎ±)
            st.markdown("#### ğŸ“‹ ÎŒÎ»Î± Ï„Î± Î”ÎµÎ´Î¿Î¼Î­Î½Î±")
            st.dataframe(
                df,
                use_container_width=True,
                height=600
            )
            
            # Download button
            st.markdown("#### ğŸ’¾ ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î± Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½")
            
            # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Excel Î±ÏÏ‡ÎµÎ¯Î¿Ï…
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='e-EFKA_Data', index=False)
            
            output.seek(0)
            
            # Download button
            st.download_button(
                label="ğŸ“¥ ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Excel Î±ÏÏ‡ÎµÎ¯Î¿",
                data=output.getvalue(),
                file_name=f"efka_data_{st.session_state['uploaded_file'].name}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
            
            # Reset button
            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                if st.button("ğŸ”„ ÎÎ­Î¿ Î‘ÏÏ‡ÎµÎ¯Î¿", use_container_width=True):
                    # Reset session state
                    for key in ['file_uploaded', 'processing_done', 'uploaded_file', 'extracted_data']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()
            
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î®")
            
            # Reset button
            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                if st.button("ğŸ”„ Î”Î¿ÎºÎ¹Î¼Î¬ÏƒÏ„Îµ ÎÎ±Î½Î¬", use_container_width=True):
                    # Reset session state
                    for key in ['file_uploaded', 'processing_done', 'uploaded_file', 'extracted_data']:
                        if key in st.session_state:
                            del st.session_state[key]
                    st.rerun()

if __name__ == "__main__":
    main()


