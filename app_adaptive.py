#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
e-EFKA PDF Data Extractor - Adaptive Version
Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® Î­ÎºÎ´Î¿ÏƒÎ· Ï€Î¿Ï… Î´Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ Ï€Î¿Î»Î»Î­Ï‚ Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯ÏƒÎµÎ¹Ï‚
"""

import streamlit as st
import pandas as pd
import io
import tempfile
import os
import re
from pathlib import Path

# Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î®Ï‚ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏÎ½ PDF readers
try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False

try:
    import fitz  # PyMuPDF
    PYMUPDF_AVAILABLE = True
except ImportError:
    PYMUPDF_AVAILABLE = False

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÏƒÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(
    page_title="e-EFKA PDF Extractor (Adaptive)",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
    }
    .info-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
    }
    .warning-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
    }
</style>
""", unsafe_allow_html=True)

def extract_tables_adaptive(pdf_path):
    """
    Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€Î¹Î½Î¬ÎºÏ‰Î½ Î¼Îµ Ï€Î¿Î»Î»Î­Ï‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚
    """
    import pdfplumber
    
    all_tables = []
    
    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
        st.info(f"ğŸ“„ Î£ÏÎ½Î¿Î»Î¿ ÏƒÎµÎ»Î¯Î´Ï‰Î½: {total_pages}")
        
        for page_num, page in enumerate(pdf.pages):
            if page_num < 1:  # Î Î±ÏÎ±ÎºÎ¬Î¼Ï€Ï„Î¿Ï…Î¼Îµ Ï„Î·Î½ Ï€ÏÏÏ„Î· ÏƒÎµÎ»Î¯Î´Î±
                continue
                
            st.markdown(f"### ğŸ” Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î£ÎµÎ»Î¯Î´Î±Ï‚ {page_num + 1}")
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 1: ÎšÎ±Î½Î¿Î½Î¹ÎºÎ® ÎµÎ¾Î±Î³Ï‰Î³Î® Ï€Î¹Î½Î¬ÎºÏ‰Î½
            tables = page.extract_tables()
            st.info(f"ğŸ“Š Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(tables)} Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ® Î¼Î­Î¸Î¿Î´Î¿")
            
            if len(tables) >= 2:
                second_table = tables[1]
                if second_table and len(second_table) > 1:
                    df = pd.DataFrame(second_table[1:], columns=second_table[0])
                    df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                    all_tables.append(df)
                    st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (ÎºÎ±Î½Î¿Î½Î¹ÎºÎ® Î¼Î­Î¸Î¿Î´Î¿Ï‚)")
                    continue
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 2: Î•Î¾Î±Î³Ï‰Î³Î® Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ Ï€Î±ÏÎ±Î¼Î­Ï„ÏÎ¿Ï…Ï‚
            try:
                tables_alt = page.extract_tables(table_settings={
                    "vertical_strategy": "lines_strict",
                    "horizontal_strategy": "lines_strict"
                })
                st.info(f"ğŸ“Š Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(tables_alt)} Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ strict lines")
                
                if len(tables_alt) >= 2:
                    second_table = tables_alt[1]
                    if second_table and len(second_table) > 1:
                        df = pd.DataFrame(second_table[1:], columns=second_table[0])
                        df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                        all_tables.append(df)
                        st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (strict lines)")
                        continue
            except Exception as e:
                st.warning(f"âš ï¸ Strict lines Î±Ï€Î­Ï„Ï…Ï‡Îµ: {str(e)}")
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 3: Î•Î¾Î±Î³Ï‰Î³Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Ï€Î¹Î½Î¬ÎºÏ‰Î½
            try:
                all_tables_page = page.extract_tables()
                if all_tables_page:
                    # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿ Ï€Î¯Î½Î±ÎºÎ±
                    largest_table = max(all_tables_page, key=len)
                    if largest_table and len(largest_table) > 1:
                        df = pd.DataFrame(largest_table[1:], columns=largest_table[0])
                        df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                        all_tables.append(df)
                        st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (Î¼ÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚)")
                        continue
            except Exception as e:
                st.warning(f"âš ï¸ ÎœÎµÎ³Î±Î»ÏÏ„ÎµÏÎ¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Î±Ï€Î­Ï„Ï…Ï‡Îµ: {str(e)}")
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 4: Text-based parsing
            try:
                text = page.extract_text()
                if text and len(text) > 100:
                    st.info(f"ğŸ“ Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(text)} Ï‡Î±ÏÎ±ÎºÏ„Î®ÏÎµÏ‚ ÎºÎµÎ¹Î¼Î­Î½Î¿Ï…")
                    
                    # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± Ï€Î¯Î½Î±ÎºÎµÏ‚ ÏƒÏ„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿
                    table_data = parse_text_for_tables(text, page_num + 1)
                    if table_data and len(table_data) > 1:
                        df = pd.DataFrame(table_data[1:], columns=table_data[0])
                        df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                        all_tables.append(df)
                        st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (text parsing)")
                        continue
            except Exception as e:
                st.warning(f"âš ï¸ Text parsing Î±Ï€Î­Ï„Ï…Ï‡Îµ: {str(e)}")
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 6: Î•Î¾Î±Î³Ï‰Î³Î® ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ Ï€Î¹Î½Î¬ÎºÏ‰Î½ (fallback)
            try:
                all_tables_page = page.extract_tables()
                if all_tables_page:
                    # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Ï€Î¯Î½Î±ÎºÎµÏ‚, ÏŒÏ‡Î¹ Î¼ÏŒÎ½Î¿ Ï„Î¿Î½ Î´ÎµÏÏ„ÎµÏÎ¿
                    for table_idx, table in enumerate(all_tables_page):
                        if table and len(table) > 1:
                            df = pd.DataFrame(table[1:], columns=table[0])
                            df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                            df['Î Î¯Î½Î±ÎºÎ±Ï‚'] = table_idx + 1
                            all_tables.append(df)
                            st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (Ï€Î¯Î½Î±ÎºÎ±Ï‚ {table_idx + 1})")
            except Exception as e:
                st.warning(f"âš ï¸ Fallback extraction Î±Ï€Î­Ï„Ï…Ï‡Îµ: {str(e)}")
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 7: Î•Î¾Î±Î³Ï‰Î³Î® Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÏÏ…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚
            try:
                tables_alt2 = page.extract_tables(table_settings={
                    "vertical_strategy": "text",
                    "horizontal_strategy": "text"
                })
                st.info(f"ğŸ“Š Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(tables_alt2)} Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ text strategy")
                
                if tables_alt2:
                    for table_idx, table in enumerate(tables_alt2):
                        if table and len(table) > 1:
                            df = pd.DataFrame(table[1:], columns=table[0])
                            df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                            df['Î Î¯Î½Î±ÎºÎ±Ï‚'] = table_idx + 1
                            all_tables.append(df)
                            st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (text strategy, Ï€Î¯Î½Î±ÎºÎ±Ï‚ {table_idx + 1})")
            except Exception as e:
                st.warning(f"âš ï¸ Text strategy Î±Ï€Î­Ï„Ï…Ï‡Îµ: {str(e)}")
            
            # Î£Ï„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® 5: Î•Î¾Î±Î³Ï‰Î³Î® Î¼Îµ PyMuPDF
            if PYMUPDF_AVAILABLE:
                try:
                    import fitz
                    doc = fitz.open(pdf_path)
                    page_pymupdf = doc[page_num]
                    tables_pymupdf = page_pymupdf.find_tables()
                    
                    if len(tables_pymupdf) >= 2:
                        second_table = tables_pymupdf[1]
                        table_data = second_table.extract()
                        if table_data and len(table_data) > 1:
                            df = pd.DataFrame(table_data[1:], columns=table_data[0])
                            df['Î£ÎµÎ»Î¯Î´Î±'] = page_num + 1
                            all_tables.append(df)
                            st.success(f"âœ… Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î•Î¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ (PyMuPDF)")
                            doc.close()
                            continue
                    doc.close()
                except Exception as e:
                    st.warning(f"âš ï¸ PyMuPDF Î±Ï€Î­Ï„Ï…Ï‡Îµ: {str(e)}")
            
            st.warning(f"âš ï¸ Î£ÎµÎ»Î¯Î´Î± {page_num + 1}: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï€Î¯Î½Î±ÎºÎ±Ï‚ Î¼Îµ ÎºÎ±Î¼Î¯Î± ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ®")
    
    return all_tables

def parse_text_for_tables(text, page_num):
    """
    Î‘Î½Î±Î»ÏÎµÎ¹ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Î³Î¹Î± Î½Î± Î²ÏÎµÎ¹ Ï€Î¯Î½Î±ÎºÎµÏ‚
    """
    lines = text.split('\n')
    
    # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± Î³ÏÎ±Î¼Î¼Î­Ï‚ Ï€Î¿Ï… Î¼Î¿Î¹Î¬Î¶Î¿Ï…Î½ Î¼Îµ Ï€Î¯Î½Î±ÎºÎ±
    table_lines = []
    in_table = False
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # Î¨Î¬Ï‡Î½Î¿Ï…Î¼Îµ Î³Î¹Î± patterns Ï€Î¿Ï… Ï…Ï€Î¿Î´ÎµÎ¹ÎºÎ½ÏÎ¿Ï…Î½ Ï€Î¯Î½Î±ÎºÎ±
        if (re.search(r'\d{1,2}/\d{1,2}/\d{4}', line) or  # Î—Î¼ÎµÏÎ¿Î¼Î·Î½Î¯ÎµÏ‚
            re.search(r'[\d,]+\.\d{2}', line) or  # Î Î¿ÏƒÎ¬
            line.count(' ') > 3 or  # Î Î¿Î»Î»Î¬ ÎºÎµÎ½Î¬
            '\t' in line):  # Tabs
            
            table_lines.append(line)
            in_table = True
        elif in_table and len(table_lines) > 0:
            # Î‘Î½ ÎµÎ¯Ï‡Î±Î¼Îµ Î²ÏÎµÎ¹ Ï€Î¯Î½Î±ÎºÎ± Î±Î»Î»Î¬ Ï„ÏÏÎ± Î´ÎµÎ½ Î²ÏÎ¯ÏƒÎºÎ¿Ï…Î¼Îµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
            if len(table_lines) > 5:  # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ Î±ÏÎºÎµÏ„Î­Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚
                break
            else:
                table_lines = []  # Reset Î±Î½ Î´ÎµÎ½ Î­Ï‡Î¿Ï…Î¼Îµ Î±ÏÎºÎµÏ„Î­Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚
                in_table = False
    
    if len(table_lines) < 3:
        return None
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ headers
    headers = ['Î£Ï„Î®Î»Î·_1', 'Î£Ï„Î®Î»Î·_2', 'Î£Ï„Î®Î»Î·_3', 'Î£Ï„Î®Î»Î·_4', 'Î£Ï„Î®Î»Î·_5', 'Î£Ï„Î®Î»Î·_6']
    
    # ÎœÎµÏ„Î±Ï„ÏÎ­Ï€Î¿Ï…Î¼Îµ Ï„Î¹Ï‚ Î³ÏÎ±Î¼Î¼Î­Ï‚ ÏƒÎµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    data = [headers]
    for line in table_lines:
        # Î§Ï‰ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î· Î³ÏÎ±Î¼Î¼Î® ÏƒÎµ ÏƒÏ„Î®Î»ÎµÏ‚
        parts = line.split()
        if len(parts) >= 3:  # Î‘Î½ Î­Ï‡ÎµÎ¹ Î±ÏÎºÎµÏ„Î­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚
            # Î£Ï…Î¼Ï€Î»Î·ÏÏÎ½Î¿Ï…Î¼Îµ Î¼Îµ ÎºÎµÎ½Î¬ Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
            while len(parts) < len(headers):
                parts.append('')
            data.append(parts[:len(headers)])
    
    return data if len(data) > 1 else None

def extract_efka_data_adaptive(uploaded_file):
    """
    Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® ÎµÎ¾Î±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
    """
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î­Î½Î± Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_path = tmp_file.name
    
    try:
        st.markdown("### ğŸ” Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ· PDF")
        
        # Î•Î¾Î¬Î³Î¿Ï…Î¼Îµ Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® Î¼Î­Î¸Î¿Î´Î¿
        all_tables = extract_tables_adaptive(tmp_path)
        
        if not all_tables:
            st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€Î¯Î½Î±ÎºÎµÏ‚ ÏƒÏ„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿")
            return pd.DataFrame()
        
        # Î£Ï…Î½Î´Ï…Î¬Î¶Î¿Ï…Î¼Îµ ÏŒÎ»Î± Ï„Î± DataFrames
        with st.spinner("Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½..."):
            combined_df = pd.concat(all_tables, ignore_index=True)
        
        st.success(f"ğŸ‰ Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ ÎµÎ¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(combined_df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ {len(all_tables)} Ï€Î¯Î½Î±ÎºÎµÏ‚")
        return combined_df
    
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎ¾Î±Î³Ï‰Î³Î®: {str(e)}")
        return pd.DataFrame()
    
    finally:
        # Î”Î¹Î±Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)

def main():
    """ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï„Î·Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚"""
    
    # Header
    st.markdown('<h1 class="main-header">ğŸ“„ e-EFKA PDF Data Extractor (Adaptive)</h1>', unsafe_allow_html=True)
    
    # Sidebar Î¼Îµ Î¿Î´Î·Î³Î¯ÎµÏ‚
    with st.sidebar:
        st.markdown("## ğŸ“‹ ÎŸÎ´Î·Î³Î¯ÎµÏ‚")
        st.markdown("""
        1. **Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ PDF Î±ÏÏ‡ÎµÎ¯Î¿** e-EFKA
        2. **Î Î±Ï„Î®ÏƒÏ„Îµ "Î•Î¾Î±Î³Ï‰Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"**
        3. **Î ÏÎ¿Î²Î¬Î»ÎµÏ„Îµ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±** ÏƒÏ„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ±
        4. **ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ Excel** Î±ÏÏ‡ÎµÎ¯Î¿
        """)
        
        st.markdown("## ğŸ”§ Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ® ÎœÎ­Î¸Î¿Î´Î¿Ï‚")
        st.markdown("""
        **Î‘Ï…Ï„Î® Î· Î­ÎºÎ´Î¿ÏƒÎ·:**
        - **5 Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚** Î±Î½Î¬ ÏƒÎµÎ»Î¯Î´Î±
        - **Fallback system** - Î±Î½ Î¼Î¹Î± Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹, Î´Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ Ï„Î·Î½ ÎµÏ€ÏŒÎ¼ÎµÎ½Î·
        - **Flexible parsing** Î³Î¹Î± ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Ï„ÏÏ€Î¿Ï…Ï‚ Ï€Î¹Î½Î¬ÎºÏ‰Î½
        - **Multiple libraries** (pdfplumber, PyMuPDF)
        """)
        
        st.markdown("## âš ï¸ Î£Î·Î¼Î±Î½Ï„Î¹ÎºÎ¬")
        st.markdown("""
        - Î•Î¾Î¬Î³ÎµÎ¹ Î±Ï€ÏŒ **ÏƒÎµÎ»Î¯Î´Î± 2** ÎºÎ±Î¹ Î¼ÎµÏ„Î¬
        - **Î”Î¿ÎºÎ¹Î¼Î¬Î¶ÎµÎ¹ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚** Î³Î¹Î± ÎºÎ¬Î¸Îµ ÏƒÎµÎ»Î¯Î´Î±
        - **Automatic fallback** Î±Î½ Î¼Î¹Î± ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ® Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹
        - **Detailed logging** Î³Î¹Î± ÎºÎ¬Î¸Îµ Ï€ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î±
        """)
    
    # ÎšÏÏÎ¹Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ“¤ Î‘Î½Î­Î²Î±ÏƒÎ¼Î± PDF Î‘ÏÏ‡ÎµÎ¯Î¿Ï…")
        
        # File uploader
        uploaded_file = st.file_uploader(
            "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ PDF Î±ÏÏ‡ÎµÎ¯Î¿ e-EFKA",
            type=['pdf'],
            help="Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î¸Î­Î»ÎµÏ„Îµ Î½Î± Î±Î½Î±Î»ÏÏƒÎµÏ„Îµ"
        )
        
        if uploaded_file is not None:
            st.success(f"âœ… Î‘Î½ÎµÎ²Î»Î®Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿: {uploaded_file.name}")
            st.info(f"ğŸ“Š ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {uploaded_file.size:,} bytes")
    
    with col2:
        st.markdown("### âš™ï¸ Î•Î½Î­ÏÎ³ÎµÎ¹ÎµÏ‚")
        
        if uploaded_file is not None:
            if st.button("ğŸš€ Î•Î¾Î±Î³Ï‰Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½", type="primary", use_container_width=True):
                # Î•Î¾Î±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
                df = extract_efka_data_adaptive(uploaded_file)
                
                if not df.empty:
                    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ session state
                    st.session_state['extracted_data'] = df
                    st.session_state['filename'] = uploaded_file.name
                    st.rerun()
        else:
            st.info("Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï€ÏÏÏ„Î± Î­Î½Î± PDF Î±ÏÏ‡ÎµÎ¯Î¿")
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
    if 'extracted_data' in st.session_state and not st.session_state['extracted_data'].empty:
        st.markdown("---")
        st.markdown("### ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î•Î¾Î±Î³Ï‰Î³Î®Ï‚")
        
        df = st.session_state['extracted_data']
        
        # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î“ÏÎ±Î¼Î¼Î­Ï‚", len(df))
        with col2:
            st.metric("Î£Ï„Î®Î»ÎµÏ‚", len(df.columns))
        with col3:
            st.metric("Î£ÎµÎ»Î¯Î´ÎµÏ‚", df['Î£ÎµÎ»Î¯Î´Î±'].nunique() if 'Î£ÎµÎ»Î¯Î´Î±' in df.columns else 0)
        with col4:
            st.metric("ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ DataFrame", f"{df.memory_usage(deep=True).sum() / 1024:.1f} KB")
        
        # Î ÏÎ¿Î²Î¿Î»Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        st.markdown("#### ğŸ“‹ Î ÏÎ¿Î²Î¿Î»Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
        
        # Î¦Î¯Î»Ï„ÏÎ±
        if 'Î£ÎµÎ»Î¯Î´Î±' in df.columns:
            pages = sorted(df['Î£ÎµÎ»Î¯Î´Î±'].unique())
            
            # Î•Î¼Ï†Î±Î½Î¯Î¶Î¿Ï…Î¼Îµ ÏŒÎ»ÎµÏ‚ Ï„Î¹Ï‚ ÏƒÎµÎ»Î¯Î´ÎµÏ‚ Ï€Î¿Ï… Î­Ï‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î±
            st.info(f"ğŸ“Š Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼ÎµÏ‚ ÏƒÎµÎ»Î¯Î´ÎµÏ‚ Î¼Îµ Î´ÎµÎ´Î¿Î¼Î­Î½Î±: {', '.join(map(str, pages))}")
            
            selected_pages = st.multiselect(
                "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ ÏƒÎµÎ»Î¯Î´ÎµÏ‚ Î³Î¹Î± Ï€ÏÎ¿Î²Î¿Î»Î®:",
                options=pages,
                default=pages  # Î ÏÎ¿ÎµÏ€Î¹Î»Î¿Î³Î®: ÏŒÎ»ÎµÏ‚ Î¿Î¹ ÏƒÎµÎ»Î¯Î´ÎµÏ‚
            )
            
            if selected_pages:
                filtered_df = df[df['Î£ÎµÎ»Î¯Î´Î±'].isin(selected_pages)]
            else:
                filtered_df = df
        else:
            filtered_df = df
        
        # Î Î»Î®Î¸Î¿Ï‚ Î³ÏÎ±Î¼Î¼ÏÎ½ Ï€ÏÎ¿Ï‚ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
        max_rows = min(500, len(filtered_df))  # Î‘Ï…Î¾Î¬Î½Î¿Ï…Î¼Îµ Ï„Î¿ Î¼Î­Î³Î¹ÏƒÏ„Î¿ ÏŒÏÎ¹Î¿
        rows_to_show = st.slider("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³ÏÎ±Î¼Î¼ÏÎ½ Ï€ÏÎ¿Ï‚ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·:", 10, max_rows, min(50, max_rows))
        
        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î³Î¹Î± Ï„Î¹Ï‚ ÎµÏ€Î¹Î»ÎµÎ³Î¼Î­Î½ÎµÏ‚ ÏƒÎµÎ»Î¯Î´ÎµÏ‚
        if 'Î£ÎµÎ»Î¯Î´Î±' in filtered_df.columns:
            page_stats = filtered_df['Î£ÎµÎ»Î¯Î´Î±'].value_counts().sort_index()
            st.info(f"ğŸ“Š Î“ÏÎ±Î¼Î¼Î­Ï‚ Î±Î½Î¬ ÏƒÎµÎ»Î¯Î´Î±: {dict(page_stats)}")
        
        # Î Î¯Î½Î±ÎºÎ±Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        st.dataframe(
            filtered_df.head(rows_to_show),
            use_container_width=True,
            height=400
        )
        
        # Download button
        st.markdown("#### ğŸ’¾ ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î± Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½")
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Excel Î±ÏÏ‡ÎµÎ¯Î¿Ï…
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='e-EFKA_Data', index=False)
        
        output.seek(0)
        
        # Download button
        st.download_button(
            label="ğŸ“¥ ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Excel Î±ÏÏ‡ÎµÎ¯Î¿",
            data=output.getvalue(),
            file_name=f"efka_data_{st.session_state.get('filename', 'extracted')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        # Clear button
        if st.button("ğŸ—‘ï¸ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½", use_container_width=True):
            if 'extracted_data' in st.session_state:
                del st.session_state['extracted_data']
            if 'filename' in st.session_state:
                del st.session_state['filename']
            st.rerun()

if __name__ == "__main__":
    main()
