#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
e-EFKA PDF Data Extractor - Streamlit Web App
Web ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ Î±Ï€ÏŒ PDF Î±ÏÏ‡ÎµÎ¯Î± e-EFKA
"""

import streamlit as st
import camelot
import pandas as pd
import io
import tempfile
import os
from pathlib import Path

# Î¡ÏÎ¸Î¼Î¹ÏƒÎ· ÏƒÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(
    page_title="e-EFKA PDF Extractor",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS Î³Î¹Î± ÎºÎ±Î»ÏÏ„ÎµÏÎ· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
    }
    .info-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        color: #0c5460;
    }
</style>
""", unsafe_allow_html=True)

def extract_efka_data_from_upload(uploaded_file):
    """
    Î•Î¾Î¬Î³ÎµÎ¹ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ Î±Î½ÎµÎ²Î±ÏƒÎ¼Î­Î½Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿
    
    Args:
        uploaded_file: Streamlit uploaded file object
    
    Returns:
        pd.DataFrame: Î¤Î± ÎµÎ¾Î±Î³ÏŒÎ¼ÎµÎ½Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    """
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ¼Îµ Î­Î½Î± Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_path = tmp_file.name
    
    try:
        # Î›Î¯ÏƒÏ„Î± Î³Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏŒÎ»Ï‰Î½ Ï„Ï‰Î½ DataFrames
        all_dataframes = []
        
        # Î”Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ Ï„Î¿ PDF
        with st.spinner("Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· PDF Î±ÏÏ‡ÎµÎ¯Î¿Ï…..."):
            try:
                tables = camelot.read_pdf(tmp_path, pages='all', flavor='lattice')
            except Exception as e:
                if "Ghostscript" in str(e):
                    st.error("âŒ Î¤Î¿ Ghostscript Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ ÎµÎ³ÎºÎ±Ï„ÎµÏƒÏ„Î·Î¼Î­Î½Î¿!")
                    st.info("""
                    **Î“Î¹Î± Î½Î± ÎµÎ³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÎµÏ„Îµ Ï„Î¿ Ghostscript:**
                    
                    1. ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Î±Ï€ÏŒ: https://www.ghostscript.com/download/gsdnld.html
                    2. Î•Î³ÎºÎ±Ï„Î±ÏƒÏ„Î®ÏƒÏ„Îµ Ï„Î¿ Ghostscript
                    3. Î ÏÎ¿ÏƒÎ¸Î­ÏƒÏ„Îµ Ï„Î¿ ÏƒÏ„Î¿ PATH Ï„Î¿Ï… ÏƒÏ…ÏƒÏ„Î®Î¼Î±Ï„Î¿Ï‚
                    4. Î•Ï€Î±Î½ÎµÎºÎºÎ¹Î½Î®ÏƒÏ„Îµ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®
                    
                    **Î•Î½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ¬, Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î¿ command-line script:**
                    `python efka_pdf_extractor.py`
                    """)
                    return pd.DataFrame()
                else:
                    raise e
        
        if not tables:
            st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Ï€Î¯Î½Î±ÎºÎµÏ‚ ÏƒÏ„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿")
            return pd.DataFrame()
        
        st.info(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(tables)} Ï€Î¯Î½Î±ÎºÎµÏ‚ ÏƒÏ…Î½Î¿Î»Î¹ÎºÎ¬")
        
        # ÎŸÎ¼Î±Î´Î¿Ï€Î¿Î¹Î¿ÏÎ¼Îµ Ï„Î¿Ï…Ï‚ Ï€Î¯Î½Î±ÎºÎµÏ‚ Î±Î½Î¬ ÏƒÎµÎ»Î¯Î´Î±
        pages_dict = {}
        for table in tables:
            page_num = table.page
            if page_num not in pages_dict:
                pages_dict[page_num] = []
            pages_dict[page_num].append(table)
        
        # Î•Î¾Î¬Î³Î¿Ï…Î¼Îµ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î±Ï€ÏŒ ÎºÎ¬Î¸Îµ ÏƒÎµÎ»Î¯Î´Î± (Î¾ÎµÎºÎ¹Î½ÏÎ½Ï„Î±Ï‚ Î±Ï€ÏŒ ÏƒÎµÎ»Î¯Î´Î± 2)
        progress_bar = st.progress(0)
        total_pages = len([p for p in pages_dict.keys() if p >= 2])
        processed_pages = 0
        
        for page_num in sorted(pages_dict.keys()):
            if page_num < 2:  # Î Î±ÏÎ±ÎºÎ¬Î¼Ï€Ï„Î¿Ï…Î¼Îµ Ï„Î·Î½ Ï€ÏÏÏ„Î· ÏƒÎµÎ»Î¯Î´Î±
                continue
                
            with st.spinner(f"Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÏƒÎµÎ»Î¯Î´Î±Ï‚ {page_num}..."):
                page_tables = pages_dict[page_num]
                
                if len(page_tables) >= 2:
                    # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î¿Î½ Î´ÎµÏÏ„ÎµÏÎ¿ Ï€Î¯Î½Î±ÎºÎ± (index 1)
                    second_table = page_tables[1]
                    df = second_table.df
                    
                    # Î ÏÎ¿ÏƒÎ¸Î­Ï„Î¿Ï…Î¼Îµ Î¼Î¹Î± ÏƒÏ„Î®Î»Î· Î¼Îµ Ï„Î¿Î½ Î±ÏÎ¹Î¸Î¼ÏŒ ÏƒÎµÎ»Î¯Î´Î±Ï‚
                    df['Î£ÎµÎ»Î¯Î´Î±'] = page_num
                    
                    all_dataframes.append(df)
                    st.success(f"Î£ÎµÎ»Î¯Î´Î± {page_num}: Î•Î¾Î®Ï‡Î¸Î·ÎºÎ±Î½ {len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚")
                else:
                    st.warning(f"Î£ÎµÎ»Î¯Î´Î± {page_num}: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î´ÎµÏÏ„ÎµÏÎ¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚")
            
            processed_pages += 1
            progress_bar.progress(processed_pages / total_pages)
        
        # Î£Ï…Î½Î´Ï…Î¬Î¶Î¿Ï…Î¼Îµ ÏŒÎ»Î± Ï„Î± DataFrames
        if all_dataframes:
            with st.spinner("Î£Ï…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½..."):
                combined_df = pd.concat(all_dataframes, ignore_index=True)
            
            st.success(f"Î£Ï…Î½Î¿Î»Î¹ÎºÎ¬ ÎµÎ¾Î®Ï‡Î¸Î·ÏƒÎ±Î½ {len(combined_df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
            return combined_df
        else:
            st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î± Î³Î¹Î± ÎµÎ¾Î±Î³Ï‰Î³Î®")
            return pd.DataFrame()
    
    except Exception as e:
        st.error(f"Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î·Î½ ÎµÎ¾Î±Î³Ï‰Î³Î®: {str(e)}")
        return pd.DataFrame()
    
    finally:
        # Î”Î¹Î±Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î¿ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½ÏŒ Î±ÏÏ‡ÎµÎ¯Î¿
        if os.path.exists(tmp_path):
            os.unlink(tmp_path)

def main():
    """ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Ï„Î·Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚"""
    
    # Header
    st.markdown('<h1 class="main-header">ğŸ“„ e-EFKA PDF Data Extractor</h1>', unsafe_allow_html=True)
    
    # Sidebar Î¼Îµ Î¿Î´Î·Î³Î¯ÎµÏ‚
    with st.sidebar:
        st.markdown("## ğŸ“‹ ÎŸÎ´Î·Î³Î¯ÎµÏ‚")
        st.markdown("""
        1. **Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ PDF Î±ÏÏ‡ÎµÎ¯Î¿** e-EFKA
        2. **Î Î±Ï„Î®ÏƒÏ„Îµ "Î•Î¾Î±Î³Ï‰Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½"**
        3. **Î ÏÎ¿Î²Î¬Î»ÎµÏ„Îµ Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±** ÏƒÏ„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ±
        4. **ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ Excel** Î±ÏÏ‡ÎµÎ¯Î¿
        
        **Î£Ï„Î®Î»ÎµÏ‚ Ï€Î¿Ï… ÎµÎ¾Î¬Î³Î¿Î½Ï„Î±Î¹:**
        - Î‘Ï€ÏŒ
        - ÎˆÏ‰Ï‚
        - Î—Î¼Î­ÏÎµÏ‚
        - ÎœÎ¹ÎºÏ„Î­Ï‚ Î±Ï€Î¿Î´Î¿Ï‡Î­Ï‚
        - Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î•Î¹ÏƒÏ†Î¿ÏÎ­Ï‚
        - Î‘/Îœ Î•ÏÎ³Î¿Î´ÏŒÏ„Î·
        """)
        
        st.markdown("## âš ï¸ Î£Î·Î¼Î±Î½Ï„Î¹ÎºÎ¬")
        st.markdown("""
        - Î¤Î¿ PDF Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î­Ï‡ÎµÎ¹ Ï€Î¯Î½Î±ÎºÎµÏ‚ Î¼Îµ grid lines
        - Î•Î¾Î¬Î³ÎµÏ„Î±Î¹ Î¿ **Î´ÎµÏÏ„ÎµÏÎ¿Ï‚ Ï€Î¯Î½Î±ÎºÎ±Ï‚** Î±Ï€ÏŒ ÎºÎ¬Î¸Îµ ÏƒÎµÎ»Î¯Î´Î±
        - ÎÎµÎºÎ¹Î½Î¬ÎµÎ¹ Î±Ï€ÏŒ **ÏƒÎµÎ»Î¯Î´Î± 2**
        - Î¤Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î± Ï€Î±ÏÎ±Î¼Î­Î½Î¿Ï…Î½ **Î±ÎºÎ±Ï„Î­ÏÎ³Î±ÏƒÏ„Î±**
        """)
    
    # ÎšÏÏÎ¹Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ“¤ Î‘Î½Î­Î²Î±ÏƒÎ¼Î± PDF Î‘ÏÏ‡ÎµÎ¯Î¿Ï…")
        
        # File uploader
        uploaded_file = st.file_uploader(
            "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ PDF Î±ÏÏ‡ÎµÎ¯Î¿ e-EFKA",
            type=['pdf'],
            help="Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï„Î¿ PDF Î±ÏÏ‡ÎµÎ¯Î¿ Ï€Î¿Ï… Î¸Î­Î»ÎµÏ„Îµ Î½Î± Î±Î½Î±Î»ÏÏƒÎµÏ„Îµ"
        )
        
        if uploaded_file is not None:
            st.success(f"âœ… Î‘Î½ÎµÎ²Î»Î®Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿: {uploaded_file.name}")
            st.info(f"ğŸ“Š ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Î¿Ï…: {uploaded_file.size:,} bytes")
    
    with col2:
        st.markdown("### âš™ï¸ Î•Î½Î­ÏÎ³ÎµÎ¹ÎµÏ‚")
        
        if uploaded_file is not None:
            if st.button("ğŸš€ Î•Î¾Î±Î³Ï‰Î³Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½", type="primary", use_container_width=True):
                # Î•Î¾Î±Î³Ï‰Î³Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
                df = extract_efka_data_from_upload(uploaded_file)
                
                if not df.empty:
                    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÏƒÏ„Î¿ session state
                    st.session_state['extracted_data'] = df
                    st.session_state['filename'] = uploaded_file.name
                    st.rerun()
        else:
            st.info("Î‘Î½ÎµÎ²Î¬ÏƒÏ„Îµ Ï€ÏÏÏ„Î± Î­Î½Î± PDF Î±ÏÏ‡ÎµÎ¯Î¿")
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
    if 'extracted_data' in st.session_state and not st.session_state['extracted_data'].empty:
        st.markdown("---")
        st.markdown("### ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î•Î¾Î±Î³Ï‰Î³Î®Ï‚")
        
        df = st.session_state['extracted_data']
        
        # Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Î£Ï…Î½Î¿Î»Î¹ÎºÎ­Ï‚ Î“ÏÎ±Î¼Î¼Î­Ï‚", len(df))
        with col2:
            st.metric("Î£Ï„Î®Î»ÎµÏ‚", len(df.columns))
        with col3:
            st.metric("Î£ÎµÎ»Î¯Î´ÎµÏ‚", df['Î£ÎµÎ»Î¯Î´Î±'].nunique() if 'Î£ÎµÎ»Î¯Î´Î±' in df.columns else 0)
        with col4:
            st.metric("ÎœÎ­Î³ÎµÎ¸Î¿Ï‚ DataFrame", f"{df.memory_usage(deep=True).sum() / 1024:.1f} KB")
        
        # Î ÏÎ¿Î²Î¿Î»Î® Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        st.markdown("#### ğŸ“‹ Î ÏÎ¿Î²Î¿Î»Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½")
        
        # Î¦Î¯Î»Ï„ÏÎ±
        if 'Î£ÎµÎ»Î¯Î´Î±' in df.columns:
            pages = sorted(df['Î£ÎµÎ»Î¯Î´Î±'].unique())
            selected_pages = st.multiselect(
                "Î•Ï€Î¹Î»Î­Î¾Ï„Îµ ÏƒÎµÎ»Î¯Î´ÎµÏ‚ Î³Î¹Î± Ï€ÏÎ¿Î²Î¿Î»Î®:",
                options=pages,
                default=pages[:3] if len(pages) > 3 else pages
            )
            
            if selected_pages:
                filtered_df = df[df['Î£ÎµÎ»Î¯Î´Î±'].isin(selected_pages)]
            else:
                filtered_df = df
        else:
            filtered_df = df
        
        # Î Î»Î®Î¸Î¿Ï‚ Î³ÏÎ±Î¼Î¼ÏÎ½ Ï€ÏÎ¿Ï‚ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
        rows_to_show = st.slider("Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ Î³ÏÎ±Î¼Î¼ÏÎ½ Ï€ÏÎ¿Ï‚ ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·:", 10, min(100, len(filtered_df)), 20)
        
        # Î Î¯Î½Î±ÎºÎ±Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
        st.dataframe(
            filtered_df.head(rows_to_show),
            use_container_width=True,
            height=400
        )
        
        # Download button
        st.markdown("#### ğŸ’¾ ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î± Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½")
        
        # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Excel Î±ÏÏ‡ÎµÎ¯Î¿Ï…
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='e-EFKA_Data', index=False)
        
        output.seek(0)
        
        # Download button
        st.download_button(
            label="ğŸ“¥ ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÏ„Îµ Excel Î±ÏÏ‡ÎµÎ¯Î¿",
            data=output.getvalue(),
            file_name=f"efka_data_{st.session_state.get('filename', 'extracted')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True
        )
        
        # Clear button
        if st.button("ğŸ—‘ï¸ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½", use_container_width=True):
            if 'extracted_data' in st.session_state:
                del st.session_state['extracted_data']
            if 'filename' in st.session_state:
                del st.session_state['filename']
            st.rerun()

if __name__ == "__main__":
    main()
